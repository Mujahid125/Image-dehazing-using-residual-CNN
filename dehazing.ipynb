{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TAFOByTUBHCf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn import datasets\n",
        "import time\n",
        "from datetime import timedelta\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import save_model\n",
        "import h5py as h5\n",
        "\n",
        "# Adding Seed so that random initialization is consistent\n",
        "from numpy.random import seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1Q2xXO-mB6l9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\MOHAMMAD MUJAHID\\AppData\\Local\\Temp\\ipykernel_21364\\536647320.py:1: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "seed(1)\n",
        "# from tensorflow import set_random_seed\n",
        "\n",
        "tf.random.set_seed(2)\n",
        "\n",
        "batch_size = 17\n",
        "\n",
        "# 20% of the data will automatically be used for validation\n",
        "validation_size = 0.2\n",
        "img_size = 128\n",
        "num_channels = 3\n",
        "train_path = \"/content/gdrive/MyDrive/training\"\n",
        "classes = ['GT', 'hazy']\n",
        "num_classes = len(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "petUI30pgIJb"
      },
      "outputs": [],
      "source": [
        "def load_train(train_path, image_size, classes):\n",
        "    images = []\n",
        "    labels = []\n",
        "    img_names = []\n",
        "    cls = []\n",
        "\n",
        "    print('Going to read training images')\n",
        "    for fields in classes:\n",
        "        index = classes.index(fields)\n",
        "        print('Now going to read {} files (Index: {})'.format(fields, index))\n",
        "        path = os.path.join(train_path, fields, '*.png')\n",
        "        files = glob.glob(path)\n",
        "        for fl in files:\n",
        "            image = cv2.imread(fl)\n",
        "            image = cv2.resize(image, (image_size, image_size),0,0, cv2.INTER_LINEAR)\n",
        "            image = image.astype(np.float32)\n",
        "            image = np.multiply(image, 1.0 / 255.0)\n",
        "            images.append(image)\n",
        "            label = np.zeros(len(classes))\n",
        "            label[index] = 1.0\n",
        "            labels.append(label)\n",
        "            flbase = os.path.basename(fl)\n",
        "            img_names.append(flbase)\n",
        "            cls.append(fields)\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    img_names = np.array(img_names)\n",
        "    cls = np.array(cls)\n",
        "\n",
        "    return images, labels, img_names, cls\n",
        "\n",
        "\n",
        "class DataSet(object):\n",
        "\n",
        "  def __init__(self, images, labels, img_names, cls):\n",
        "    self._num_examples = images.shape[0]\n",
        "\n",
        "    self._images = images\n",
        "    self._labels = labels\n",
        "    self._img_names = img_names\n",
        "    self._cls = cls\n",
        "    self._epochs_done = 0\n",
        "    self._index_in_epoch = 0\n",
        "\n",
        "  @property\n",
        "  def images(self):\n",
        "    return self._images\n",
        "\n",
        "  @property\n",
        "  def labels(self):\n",
        "    return self._labels\n",
        "\n",
        "  @property\n",
        "  def img_names(self):\n",
        "    return self._img_names\n",
        "\n",
        "  @property\n",
        "  def cls(self):\n",
        "    return self._cls\n",
        "\n",
        "  @property\n",
        "  def num_examples(self):\n",
        "    return self._num_examples\n",
        "\n",
        "  @property\n",
        "  def epochs_done(self):\n",
        "    return self._epochs_done\n",
        "\n",
        "  def next_batch(self, batch_size):\n",
        "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
        "    start = self._index_in_epoch\n",
        "    self._index_in_epoch += batch_size\n",
        "\n",
        "    if self._index_in_epoch > self._num_examples:\n",
        "      # After each epoch we update this\n",
        "      self._epochs_done += 1\n",
        "      start = 0\n",
        "      self._index_in_epoch = batch_size\n",
        "      assert batch_size <= self._num_examples\n",
        "    end = self._index_in_epoch\n",
        "\n",
        "    return self._images[start:end], self._labels[start:end], self._img_names[start:end], self._cls[start:end]\n",
        "\n",
        "\n",
        "def read_train_sets(train_path, image_size, classes, validation_size):\n",
        "  class DataSets(object):\n",
        "    pass\n",
        "  data_sets = DataSets()\n",
        "\n",
        "  images, labels, img_names, cls = load_train(train_path, image_size, classes)\n",
        "  images, labels, img_names, cls = shuffle(images, labels, img_names, cls)\n",
        "\n",
        "  if isinstance(validation_size, float):\n",
        "    validation_size = int(validation_size * images.shape[0])\n",
        "\n",
        "  validation_images = images[:validation_size]\n",
        "  validation_labels = labels[:validation_size]\n",
        "  validation_img_names = img_names[:validation_size]\n",
        "  validation_cls = cls[:validation_size]\n",
        "\n",
        "  train_images = images[validation_size:]\n",
        "  train_labels = labels[validation_size:]\n",
        "  train_img_names = img_names[validation_size:]\n",
        "  train_cls = cls[validation_size:]\n",
        "\n",
        "  data_sets.train = DataSet(train_images, train_labels, train_img_names, train_cls)\n",
        "  data_sets.valid = DataSet(validation_images, validation_labels, validation_img_names, validation_cls)\n",
        "\n",
        "  return data_sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-4e1pC8CBhU",
        "outputId": "4401f4bb-b3fe-491b-aeb4-734818706265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Going to read training images\n",
            "Now going to read GT files (Index: 0)\n",
            "Now going to read hazy files (Index: 1)\n",
            "Complete reading input data. Will Now print a snippet of it\n",
            "Number of files in Training-set:\t0\n",
            "Number of files in Validation-set:\t0\n",
            "WARNING:tensorflow:From C:\\Users\\MOHAMMAD MUJAHID\\AppData\\Local\\Temp\\ipykernel_21364\\4233592800.py:13: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.math.argmax` instead\n"
          ]
        }
      ],
      "source": [
        "# We shall load all the training and validation images and labels into memory using openCV and use that during training\n",
        "data = read_train_sets(train_path, img_size, classes, validation_size=validation_size)\n",
        "\n",
        "print(\"Complete reading input data. Will Now print a snippet of it\")\n",
        "print(\"Number of files in Training-set:\\t{}\".format(len(data.train.images)))\n",
        "print(\"Number of files in Validation-set:\\t{}\".format(len(data.valid.images)))\n",
        "\n",
        "session = tf.compat.v1.Session()\n",
        "x = tf.compat.v1.placeholder(tf.float32, shape=[None, img_size, img_size, num_channels], name='x')\n",
        "\n",
        "# labels\n",
        "y_true = tf.compat.v1.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
        "y_true_cls = tf.compat.v1.arg_max(y_true, dimension=1)\n",
        "\n",
        "# Network graph params\n",
        "filter_size_conv1 = 3\n",
        "num_filters_conv1 = 32\n",
        "\n",
        "filter_size_conv2 = 3\n",
        "num_filters_conv2 = 32\n",
        "\n",
        "filter_size_conv3 = 3\n",
        "num_filters_conv3 = 64\n",
        "\n",
        "fc_layer_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sxKUSJRumYp",
        "outputId": "05b46008-1b9c-4fe9-86fa-457a9ccad3c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Going to read training images\n",
            "Now going to read GT files (Index: 0)\n",
            "Now going to read hazy files (Index: 1)\n",
            "Complete reading input data. Will Now print a snippet of it\n",
            "Number of files in Training-set:\t88\n",
            "Number of files in Validation-set:\t22\n"
          ]
        }
      ],
      "source": [
        "# def load_train(train_path, image_size, classes):\n",
        "#     images = []\n",
        "#     labels = []\n",
        "#     img_names = []\n",
        "#     cls = []\n",
        "\n",
        "#     print('Going to read training images')\n",
        "#     for class_name in classes:\n",
        "#         index = classes.index(class_name)\n",
        "#         print('Now going to read {} files (Index: {})'.format(class_name, index))\n",
        "#         path = os.path.join(train_path, class_name, '*.png')\n",
        "#         files = glob.glob(path)\n",
        "#         for fl in files:\n",
        "#             image = cv2.imread(fl)\n",
        "#             image = cv2.resize(image, (image_size, image_size), 0, 0, cv2.INTER_LINEAR)\n",
        "#             image = image.astype(np.float32)\n",
        "#             image = np.multiply(image, 1.0 / 255.0)\n",
        "#             images.append(image)\n",
        "#             label = np.zeros(len(classes))\n",
        "#             label[index] = 1.0\n",
        "#             labels.append(label)\n",
        "#             flbase = os.path.basename(fl)\n",
        "#             img_names.append(flbase)\n",
        "#             cls.append(class_name)\n",
        "#     images = np.array(images)\n",
        "#     labels = np.array(labels)\n",
        "#     img_names = np.array(img_names)\n",
        "#     cls = np.array(cls)\n",
        "\n",
        "#     return images, labels, img_names, cls\n",
        "\n",
        "\n",
        "# class DataSet(object):\n",
        "#     def __init__(self, images, labels, img_names, cls):\n",
        "#         self._num_examples = images.shape[0]\n",
        "#         self._images = images\n",
        "#         self._labels = labels\n",
        "#         self._img_names = img_names\n",
        "#         self._cls = cls\n",
        "#         self._epochs_done = 0\n",
        "#         self._index_in_epoch = 0\n",
        "\n",
        "#     @property\n",
        "#     def images(self):\n",
        "#         return self._images\n",
        "\n",
        "#     @property\n",
        "#     def labels(self):\n",
        "#         return self._labels\n",
        "\n",
        "#     @property\n",
        "#     def img_names(self):\n",
        "#         return self._img_names\n",
        "\n",
        "#     @property\n",
        "#     def cls(self):\n",
        "#         return self._cls\n",
        "\n",
        "#     @property\n",
        "#     def num_examples(self):\n",
        "#         return self._num_examples\n",
        "\n",
        "#     @property\n",
        "#     def epochs_done(self):\n",
        "#         return self._epochs_done\n",
        "\n",
        "#     def next_batch(self, batch_size):\n",
        "#         start = self._index_in_epoch\n",
        "#         self._index_in_epoch += batch_size\n",
        "\n",
        "#         if self._index_in_epoch > self._num_examples:\n",
        "#             self._epochs_done += 1\n",
        "#             start = 0\n",
        "#             self._index_in_epoch = batch_size\n",
        "#             assert batch_size <= self._num_examples\n",
        "#         end = self._index_in_epoch\n",
        "\n",
        "#         return self._images[start:end], self._labels[start:end], self._img_names[start:end], self._cls[start:end]\n",
        "\n",
        "\n",
        "# def read_train_sets(train_path, image_size, classes, validation_size):\n",
        "#     class DataSets(object):\n",
        "#         pass\n",
        "#     data_sets = DataSets()\n",
        "\n",
        "#     images, labels, img_names, cls = load_train(train_path, image_size, classes)\n",
        "#     images, labels, img_names, cls = shuffle(images, labels, img_names, cls)\n",
        "\n",
        "#     if isinstance(validation_size, float):\n",
        "#         validation_size = int(validation_size * images.shape[0])\n",
        "\n",
        "#     validation_images = images[:validation_size]\n",
        "#     validation_labels = labels[:validation_size]\n",
        "#     validation_img_names = img_names[:validation_size]\n",
        "#     validation_cls = cls[:validation_size]\n",
        "\n",
        "#     train_images = images[validation_size:]\n",
        "#     train_labels = labels[validation_size:]\n",
        "#     train_img_names = img_names[validation_size:]\n",
        "#     train_cls = cls[validation_size:]\n",
        "\n",
        "#     data_sets.train = DataSet(train_images, train_labels, train_img_names, train_cls)\n",
        "#     data_sets.valid = DataSet(validation_images, validation_labels, validation_img_names, validation_cls)\n",
        "\n",
        "#     return data_sets\n",
        "\n",
        "# # Update the paths, image_size, classes, and validation_size with your specific values\n",
        "# train_path = '/content/gdrive/MyDrive/training'\n",
        "# image_size = 128\n",
        "# classes = ['GT', 'hazy']\n",
        "# validation_size = 0.2\n",
        "\n",
        "# data = read_train_sets(train_path, image_size, classes, validation_size=validation_size)\n",
        "\n",
        "# print(\"Complete reading input data. Will Now print a snippet of it\")\n",
        "# print(\"Number of files in Training-set:\\t{}\".format(len(data.train.images)))\n",
        "# print(\"Number of files in Validation-set:\\t{}\".format(len(data.valid.images)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KzZUPqjUCESi"
      },
      "outputs": [],
      "source": [
        "def create_weights(shape):\n",
        "    return tf.Variable(tf.random.truncated_normal(shape, stddev=0.05))\n",
        "\n",
        "\n",
        "def create_biases(size):\n",
        "    return tf.Variable(tf.constant(0.05, shape=[size]))\n",
        "\n",
        "\n",
        "def create_convolutional_layer(input,\n",
        "                               num_input_channels,\n",
        "                               conv_filter_size,\n",
        "                               num_filters):\n",
        "    # We shall define the weights that will be trained using create_weights function.\n",
        "    weights = create_weights(shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\n",
        "    # We create biases using the create_biases function. These are also trained.\n",
        "    biases = create_biases(num_filters)\n",
        "\n",
        "    # Creating the convolutional layer\n",
        "    layer = tf.compat.v1.nn.conv2d(input=input,\n",
        "                                   filter=weights,\n",
        "                                   strides=[1, 1, 1, 1],\n",
        "                                   padding='SAME')\n",
        "\n",
        "    layer += biases\n",
        "\n",
        "    # We shall be using max-pooling.\n",
        "    layer = tf.compat.v1.nn.max_pool(value=layer,\n",
        "                                     ksize=[1, 2, 2, 1],\n",
        "                                     strides=[1, 2, 2, 1],\n",
        "                                     padding='SAME')\n",
        "    # Output of pooling is fed to Relu which is the activation function for us.\n",
        "    layer = tf.compat.v1.nn.relu(layer)\n",
        "\n",
        "    return layer\n",
        "\n",
        "\n",
        "def create_flatten_layer(layer):\n",
        "    # We know that the shape of the layer will be [batch_size img_size img_size num_channels]\n",
        "    # But let's get it from the previous layer.\n",
        "    layer_shape = layer.get_shape()\n",
        "\n",
        "    # Number of features will be img_height * img_width* num_channels. But we shall calculate it in place of hard-coding it.\n",
        "    num_features = layer_shape[1:4].num_elements()\n",
        "\n",
        "    # Now, we Flatten the layer, so we shall have to reshape to num_features\n",
        "    layer = tf.reshape(layer, [-1, num_features])\n",
        "\n",
        "    return layer\n",
        "\n",
        "\n",
        "def create_fc_layer(input,\n",
        "                    num_inputs,\n",
        "                    num_outputs,\n",
        "                    use_relu=True):\n",
        "    # Let's define trainable weights and biases.\n",
        "    weights = create_weights(shape=[num_inputs, num_outputs])\n",
        "    biases = create_biases(num_outputs)\n",
        "\n",
        "    # Fully connected layer takes input x and produces wx+b.Since, these are matrices, we use matmul function in Tensorflow\n",
        "    layer = tf.matmul(input, weights) + biases\n",
        "    if use_relu:\n",
        "        layer = tf.nn.relu(layer)\n",
        "\n",
        "    return layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4lmSaGVRDAsO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\MOHAMMAD MUJAHID\\AppData\\Local\\Temp\\ipykernel_21364\\607555652.py:27: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\MOHAMMAD MUJAHID\\AppData\\Local\\Temp\\ipykernel_21364\\1326190386.py:34: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "layer_conv1 = create_convolutional_layer(input=x,\n",
        "                                         num_input_channels=num_channels,\n",
        "                                         conv_filter_size=filter_size_conv1,\n",
        "                                         num_filters=num_filters_conv1)\n",
        "layer_conv2 = create_convolutional_layer(input=layer_conv1,\n",
        "                                         num_input_channels=num_filters_conv1,\n",
        "                                         conv_filter_size=filter_size_conv2,\n",
        "                                         num_filters=num_filters_conv2)\n",
        "\n",
        "layer_conv3 = create_convolutional_layer(input=layer_conv2,\n",
        "                                         num_input_channels=num_filters_conv2,\n",
        "                                         conv_filter_size=filter_size_conv3,\n",
        "                                         num_filters=num_filters_conv3)\n",
        "\n",
        "layer_flat = create_flatten_layer(layer_conv3)\n",
        "\n",
        "layer_fc1 = create_fc_layer(input=layer_flat,\n",
        "                            num_inputs=layer_flat.get_shape()[1:4].num_elements(),\n",
        "                            num_outputs=fc_layer_size,\n",
        "                            use_relu=True)\n",
        "\n",
        "layer_fc2 = create_fc_layer(input=layer_fc1,\n",
        "                            num_inputs=fc_layer_size,\n",
        "                            num_outputs=num_classes,\n",
        "                            use_relu=False)\n",
        "\n",
        "y_pred = tf.nn.softmax(layer_fc2, name='y_pred')\n",
        "\n",
        "y_pred_cls = tf.compat.v1.arg_max(y_pred, dimension=1)\n",
        "session.run(tf.compat.v1.global_variables_initializer())\n",
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n",
        "                                                        labels=y_true)\n",
        "cost = tf.reduce_mean(cross_entropy)\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4).minimize(cost, var_list=None)\n",
        "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "session.run(tf.compat.v1.global_variables_initializer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_nXx8zMeITL9"
      },
      "outputs": [],
      "source": [
        "def show_progress(epoch, feed_dict_train, feed_dict_validate, val_loss):\n",
        "  acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
        "  val_acc = session.run(accuracy, feed_dict=feed_dict_validate)\n",
        "  msg = \"Training Epoch {0} --- Training Accuracy: {1:>6.1%}, Validation Accuracy: {2:>6.1%},  Validation Loss: {3:.3f}\"\n",
        "  print(msg.format(epoch + 1, acc, val_acc, val_loss))\n",
        "\n",
        "\n",
        "total_iterations = 0\n",
        "saver = tf.compat.v1.train.Saver()\n",
        "\n",
        "\n",
        "def train(num_iteration):\n",
        "    global total_iterations\n",
        "\n",
        "    for i in range(total_iterations,\n",
        "                   total_iterations + num_iteration):\n",
        "      x_batch, y_true_batch, _, cls_batch = data.train.next_batch(batch_size)\n",
        "      x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.next_batch(batch_size)\n",
        "      feed_dict_tr = {x: x_batch,\n",
        "                        y_true: y_true_batch}\n",
        "      feed_dict_val = {x: x_valid_batch,\n",
        "                         y_true: y_valid_batch}\n",
        "      session.run(optimizer, feed_dict=feed_dict_tr)\n",
        "\n",
        "\n",
        "      if i % int(data.train.num_examples / batch_size) == 0:\n",
        "          val_loss = session.run(cost, feed_dict=feed_dict_val)\n",
        "          epoch = int(i / int(data.train.num_examples / batch_size))\n",
        "\n",
        "          show_progress(epoch, feed_dict_tr, feed_dict_val, val_loss)\n",
        "\n",
        "\n",
        "    total_iterations += num_iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC9nHfBM2AtM",
        "outputId": "bf8672ec-cf46-4d05-ba8c-3c5b101cec47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "print(data.train.num_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWRdLf1SmsAW",
        "outputId": "eb42c052-69c1-42bd-fb15-d34380f3417d"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime();\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds in training ---\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n",
            "Cell \u001b[1;32mIn[8], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(num_iteration)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m total_iterations\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_iterations,\n\u001b[0;32m     16\u001b[0m                total_iterations \u001b[38;5;241m+\u001b[39m num_iteration):\n\u001b[1;32m---> 17\u001b[0m   x_batch, y_true_batch, _, cls_batch \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m   x_valid_batch, y_valid_batch, _, valid_cls_batch \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mvalid\u001b[38;5;241m.\u001b[39mnext_batch(batch_size)\n\u001b[0;32m     19\u001b[0m   feed_dict_tr \u001b[38;5;241m=\u001b[39m {x: x_batch,\n\u001b[0;32m     20\u001b[0m                     y_true: y_true_batch}\n",
            "Cell \u001b[1;32mIn[4], line 79\u001b[0m, in \u001b[0;36mDataSet.next_batch\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     77\u001b[0m   start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     78\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_in_epoch \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m---> 79\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m batch_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_examples\n\u001b[0;32m     80\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_in_epoch\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_images[start:end], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_labels[start:end], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_img_names[start:end], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cls[start:end]\n",
            "\u001b[1;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "start_time = time.time();\n",
        "train(100)\n",
        "print(\"--- %s seconds in training ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXvRWnAGJnDB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
